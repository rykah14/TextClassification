{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_for_method2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1TbHagT2R8Wef1KIfBjiD_rVY_XhhpItN",
      "authorship_tag": "ABX9TyPw/NYfAnTuX6jUkPiCEFhZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rykah14/TextClassification/blob/master/test_for_method2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# はじめに\n",
        "\n",
        "今回の研究はデータの組み合わせによる比較をメインに実験をした。\n",
        "\n",
        "データを準備し分類に必要なものだけ洗濯をした箇所最も重要と考える。\n",
        "\n",
        "そのためBERTの内部のパラメータの調整、エポック数の調整などは行なっておらず、Hugging Face の推奨する値、やり方で行なった。"
      ],
      "metadata": {
        "id": "QdS9j1L-1Kxk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.事前準備\n",
        "\n",
        "1.  redditデータセットをGoogleドライブにアップロードする\n",
        "1.   ColaboratoryファイルをGoogleドライブに接続する(左のサイドバーからファイルアイコンを選択し、Googleドライブと接続するアイコンを押す)\n",
        "2.   このノートブックに Google ドライブのファイルへのアクセスを許可しますか？というポップアップが出るので許可を選択する\n",
        "\n",
        "Googleドライブにアップロードされたcsvファイルを読み込む際には、ColaboratoryとGoogleドライブを接続する必要がある\n",
        "\n",
        "※csvファイルの内容をColaboratory上で書き換えることは行わなかった\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fAsfD5KbxmFP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.環境構築"
      ],
      "metadata": {
        "id": "KtAFd_Y2XrSl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "tensorflow　をインポートする　"
      ],
      "metadata": {
        "id": "mccUuJqtyRMq"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLJShceY_jYM"
      },
      "source": [
        "import tensorflow as tf "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPU環境を構築する"
      ],
      "metadata": {
        "id": "cxNA4UaZyUnc"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPjC5oBSmko1",
        "outputId": "25f7dc8a-7573-42c4-d9d8-39f3acf0c1a5"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "transformersのインストールを行う\n",
        "\n",
        "この作業をすることでHugging Face社の提供するBERTのツールが使えるようになる\n",
        "\n",
        "(https://huggingface.co/transformers/v2.2.0/index.html)\n",
        "\n",
        "BERT以外の自然言語処理のパッケージや画像処理のモデルもモデルもtransformers内に存在する"
      ],
      "metadata": {
        "id": "OwfSZ57TyYnB"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmFO1My4mv9Q",
        "outputId": "ea48aa8f-0cd2-4983-8aa0-6eb60cd42072"
      },
      "source": [
        "!pip install transformers　"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.15.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.データの準備"
      ],
      "metadata": {
        "id": "Olro2dfJXvO8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "事前準備でGoogleドライブに格納したredditデータセットをColaboratory上に入力する。\n",
        "\n",
        "ここでGoogleドライブとColaboratoryファイルが接続されていないとエラーが発生する。\n",
        "\n",
        "文章数の出力、データの中身の一例の出力は任意であるが、これらを行うことによってデータの中身の概要を知ることができる。\n",
        "\n",
        "今回のredditデータセットであれば、文章データを表すものはbodyに格納されている、カテゴリー名を表すものはsubredditであると分かる。"
      ],
      "metadata": {
        "id": "u8vLyGC1yjJt"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "7OvGefqm0d5c",
        "outputId": "a9e881ce-7158-4fec-f415-b27a0caf5b40"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/My Drive/reddit.csv\")\n",
        "\n",
        "print('Number of sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "\n",
        "df.sample(10)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sentences: 1,000,000\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-bee7e7cb-eec0-47cf-a142-715b48ca3ed5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subreddit</th>\n",
              "      <th>body</th>\n",
              "      <th>controversiality</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>968393</th>\n",
              "      <td>trashy</td>\n",
              "      <td>IMO this was the most predictable outcome and ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258918</th>\n",
              "      <td>gameofthrones</td>\n",
              "      <td>Yeah like nobody catches this. I listen endles...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>967848</th>\n",
              "      <td>videos</td>\n",
              "      <td>Maybe they were paid in chalk.</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>863196</th>\n",
              "      <td>leagueoflegends</td>\n",
              "      <td>I’m silver. I don’t play riven and I don’t pla...</td>\n",
              "      <td>0</td>\n",
              "      <td>-2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>455880</th>\n",
              "      <td>hockey</td>\n",
              "      <td>Once again. It was cancelled. It never happene...</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43443</th>\n",
              "      <td>worldnews</td>\n",
              "      <td>I'm surprised the great socialist hero is doin...</td>\n",
              "      <td>0</td>\n",
              "      <td>-32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>979418</th>\n",
              "      <td>Animemes</td>\n",
              "      <td>Someone call the cops.\\n\\nI need to guard this...</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69508</th>\n",
              "      <td>FortNiteBR</td>\n",
              "      <td>While getting your first win is great, we do n...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>329317</th>\n",
              "      <td>ChapoTrapHouse</td>\n",
              "      <td>\"this isn't *names every country the US has fu...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>488821</th>\n",
              "      <td>soccer</td>\n",
              "      <td>If Arsenal do make it into champions league, I...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bee7e7cb-eec0-47cf-a142-715b48ca3ed5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bee7e7cb-eec0-47cf-a142-715b48ca3ed5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bee7e7cb-eec0-47cf-a142-715b48ca3ed5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "              subreddit  ... score\n",
              "968393           trashy  ...     1\n",
              "258918    gameofthrones  ...     1\n",
              "967848           videos  ...     1\n",
              "863196  leagueoflegends  ...    -2\n",
              "455880           hockey  ...     3\n",
              "43443         worldnews  ...   -32\n",
              "979418         Animemes  ...     6\n",
              "69508        FortNiteBR  ...     1\n",
              "329317   ChapoTrapHouse  ...     1\n",
              "488821           soccer  ...     1\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "redditデータセットの個々のカテゴリー(subreddit)に何個文章データが格納されているのかを知る。\n",
        "\n",
        "csvファイルの形式に応じて'subreddit' ,'body'を書き換える"
      ],
      "metadata": {
        "id": "z3hrn6egzOn7"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hvs-e334xQt",
        "outputId": "a64b99b4-6ef8-4f61-fccf-b6052058c104"
      },
      "source": [
        "print(\"subreddit多いもの順50\")\n",
        "count_df = df[['subreddit','body']].groupby('subreddit').aggregate({'body':'count'}).reset_index().sort_values('subreddit',ascending=True)\n",
        "print(count_df.head(50))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "subreddit多いもの順50\n",
            "              subreddit   body\n",
            "0         AmItheAsshole  25000\n",
            "1              Animemes  25000\n",
            "2             AskReddit  25000\n",
            "3        ChapoTrapHouse  25000\n",
            "4            FortNiteBR  25000\n",
            "5              Market76  25000\n",
            "6          MortalKombat  25000\n",
            "7                Pikabu  25000\n",
            "8               RoastMe  25000\n",
            "9        Showerthoughts  25000\n",
            "10        SquaredCircle  25000\n",
            "11           The_Donald  25000\n",
            "12          apexlegends  25000\n",
            "13               asoiaf  25000\n",
            "14                  aww  25000\n",
            "15            dankmemes  25000\n",
            "16             freefolk  25000\n",
            "17                funny  25000\n",
            "18        gameofthrones  25000\n",
            "19               gaming  25000\n",
            "20             gonewild  25000\n",
            "21               hockey  25000\n",
            "22      leagueoflegends  25000\n",
            "23        marvelstudios  25000\n",
            "24                memes  25000\n",
            "25               movies  25000\n",
            "26                  nba  25000\n",
            "27                 news  25000\n",
            "28                  nfl  25000\n",
            "29                 pics  25000\n",
            "30             politics  25000\n",
            "31  relationship_advice  25000\n",
            "32               soccer  25000\n",
            "33            teenagers  25000\n",
            "34        todayilearned  25000\n",
            "35               trashy  25000\n",
            "36     unpopularopinion  25000\n",
            "37               videos  25000\n",
            "38       wallstreetbets  25000\n",
            "39            worldnews  25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "分類に使う文章データのカテゴリーと量を決める。\n",
        "\n",
        "今回は2値分類なので2種類(df_0. df_1)用意した。"
      ],
      "metadata": {
        "id": "eaxl7WwmL2wt"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4B_Ttt6VDaO",
        "outputId": "860f0919-42a0-4f05-a54d-061fdbe9ade7"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# データの読込\n",
        "\n",
        "# データの抽出\n",
        "df_0 = df.loc[df['subreddit'].isin(['news']), ['subreddit', 'body']]\n",
        "#どのカテゴリーを使うかを決めて、抽出したい情報(今回はカテゴリーを表すsubredditと文章を表すbody)を選ぶ\n",
        "df_0=df_0.replace('news',0)\n",
        "#以降の学習、検証ではint型のラベル名しかつけられないため、カテゴリーはint型の数値に置き換える\n",
        "split_dataset_0,discard_0=train_test_split(df_0, train_size=(5000/25000)) \n",
        "#必要な数だけ選択するために、train_test_splitを使ってsplit_dataset_0に分類に使う数のみ格納した\n",
        "print(\"使えるデータセット\")\n",
        "print(split_dataset_0)\n",
        "#分類に必要な数だけデータが揃っているか、カテゴリーを示すものがint型の数値になっているのかの2点を確認するためにsplit_dataset_0の中身の一部を出力する\n",
        "\n",
        "#もう1種類も同じように選択と抽出を行う\n",
        "df_1 = df.loc[df['subreddit'].isin(['worldnews']), ['subreddit', 'body']]\n",
        "df_1=df_1.replace('worldnews',1)\n",
        "split_dataset_1 ,discard_1= train_test_split(df_1, train_size=(5000/25000))\n",
        "print(\"使えるデータセット\")\n",
        "print(split_dataset_1)\n",
        "\n",
        "#以降分類数を増やす際には上記の内容をコピー＆ペーストし、必要な箇所のみを書き換える\n",
        "\n",
        "list=[]\n",
        "#分類に使う全てのデータはリストで管理する\n",
        "list.append(split_dataset_0)\n",
        "#リストに分類で使うデータを追加する\n",
        "list.append(split_dataset_1)\n",
        "\n",
        "df = pd.concat(list, sort=False)\n",
        "#listの中にデータが格納されているかの確認を行う\n",
        "#出力結果から、カテゴリーを表す箇所がint型のデータになっているか、分類に必要な数が格納されているかを確認する\n",
        "print(df)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "使えるデータセット\n",
            "        subreddit                                               body\n",
            "571205          0  I hope he's enjoying all the downvotes he's ge...\n",
            "531014          0  People do suck.  You need structured, consiste...\n",
            "157170          0  What does Eric Holder have to do with whether ...\n",
            "298437          0  Oh freedom of press, and freedom of speech.\\n\\...\n",
            "487552          0  For real, a friend of mine (17) works at a McD...\n",
            "...           ...                                                ...\n",
            "29491           0  Undergrad student who was on campus today duri...\n",
            "602658          0                Most likely they are afraid of bees\n",
            "224547          0  To be fair, they probably hadnt heard them, if...\n",
            "328433          0  So you're against social security? Firefighter...\n",
            "5427            0  There are plenty of states and campuses that a...\n",
            "\n",
            "[5000 rows x 2 columns]\n",
            "使えるデータセット\n",
            "        subreddit                                               body\n",
            "666134          1  That's the DGFiP report. They don't deal with ...\n",
            "318475          1  And he was driving at the crowd rather than away.\n",
            "350452          1  Or accept the reality that breastfeeding is ho...\n",
            "467063          1  *Sikh\\n\\nJust click \"Use suggested headline\" n...\n",
            "425003          1  If you want this man imprisoned then you have ...\n",
            "...           ...                                                ...\n",
            "555794          1  Maduro didn't hold \"sham elections\", he won th...\n",
            "334608          1  Spain's king abdicated a few years ago. It's n...\n",
            "564744          1  Front page of /r/all the only way to escape po...\n",
            "27445           1  No deflection.  You are right lots of conserva...\n",
            "108171          1  There will be protests, but in the end those c...\n",
            "\n",
            "[5000 rows x 2 columns]\n",
            "        subreddit                                               body\n",
            "571205          0  I hope he's enjoying all the downvotes he's ge...\n",
            "531014          0  People do suck.  You need structured, consiste...\n",
            "157170          0  What does Eric Holder have to do with whether ...\n",
            "298437          0  Oh freedom of press, and freedom of speech.\\n\\...\n",
            "487552          0  For real, a friend of mine (17) works at a McD...\n",
            "...           ...                                                ...\n",
            "555794          1  Maduro didn't hold \"sham elections\", he won th...\n",
            "334608          1  Spain's king abdicated a few years ago. It's n...\n",
            "564744          1  Front page of /r/all the only way to escape po...\n",
            "27445           1  No deflection.  You are right lots of conserva...\n",
            "108171          1  There will be protests, but in the end those c...\n",
            "\n",
            "[10000 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Et6IqXeskSkn",
        "outputId": "c4a88d6b-0a62-457e-a8bb-382326388cbf"
      },
      "source": [
        "print(df.sample(10))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        subreddit                                               body\n",
            "652002          1     Politics &gt; lives. These people are monsters\n",
            "536165          1  This is nuts... I'd probably be blocking any f...\n",
            "12954           0  Damn never thought id see this shit at the sch...\n",
            "196684          1  That honestly sounds even worse. Because it so...\n",
            "753182          0  how stupid do you have to be to have to pay 6....\n",
            "300274          1  Yes, the scourge of white generalizations has ...\n",
            "507353          1  If he was going to reveal it to the public any...\n",
            "234066          1  If you watch only corporate news, you'd think ...\n",
            "775984          0  3.9/4 = what %? Where isn't it a good GPA? Fan...\n",
            "577789          1  Well considering there is zero evidence to sup...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "hqjLnuCQnbfL",
        "outputId": "123b730e-c5c1-4319-cfd8-c42b51dda6fc"
      },
      "source": [
        "df.loc[df.subreddit == 0].sample(5)[['subreddit','body']]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-550dbdd4-ad95-4da7-9305-0929dbde33c7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subreddit</th>\n",
              "      <th>body</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>79691</th>\n",
              "      <td>0</td>\n",
              "      <td>Did you read your article?  You said “mass sho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>697236</th>\n",
              "      <td>0</td>\n",
              "      <td>No, people think they are less responsible now...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298421</th>\n",
              "      <td>0</td>\n",
              "      <td>Can you be next?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>608654</th>\n",
              "      <td>0</td>\n",
              "      <td>Knowing the environmental repercussions at sta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>430803</th>\n",
              "      <td>0</td>\n",
              "      <td>So let me get this straight. You think that Ma...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-550dbdd4-ad95-4da7-9305-0929dbde33c7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-550dbdd4-ad95-4da7-9305-0929dbde33c7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-550dbdd4-ad95-4da7-9305-0929dbde33c7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        subreddit                                               body\n",
              "79691           0  Did you read your article?  You said “mass sho...\n",
              "697236          0  No, people think they are less responsible now...\n",
              "298421          0                                   Can you be next?\n",
              "608654          0  Knowing the environmental repercussions at sta...\n",
              "430803          0  So let me get this straight. You think that Ma..."
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.BERTでの分類に向けた準備"
      ],
      "metadata": {
        "id": "vWCsX31EXzR6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "トークン化に向けて、カテゴリー(subreddit)と文章(body)を一旦別々のリストに格納する"
      ],
      "metadata": {
        "id": "OxQeo1a4OM0u"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4PBek_tnvi8"
      },
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "subreddits = df.subreddit.values\n",
        "bodys = df.body.values"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "文章(body)がbodysに格納され、カテゴリーとは別になっているかを確認する"
      ],
      "metadata": {
        "id": "82x6_lhpOV5I"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeM-JgfvrcU6",
        "outputId": "4af67a4a-1280-4eac-e5f1-7b8796d458ea"
      },
      "source": [
        "print(bodys[1:10])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"People do suck.  You need structured, consistent rules... ie laws.   They need to be fair, and equally applied.\\n\\nGroups of people don't do that... they get pitchforks and torches.\\n\\n&amp;#x200B;\\n\\nI am amazed this is an unpopular stance.\"\n",
            " \"What does Eric Holder have to do with whether Barr should be impeached?\\n\\nHolder didn't commit perjury or investigate FBI agents for anti-Obama bias or exempt Obama's businesses from bans on accepting foreign money.\\n\\nBarr deserves to be impeached for several reasons, but refusing the subpoena will be the cherry on top.\"\n",
            " 'Oh freedom of press, and freedom of speech.\\n\\n&amp;#x200B;\\n\\nThere really should be another amendment added in there to keep the government from stepping on those.'\n",
            " 'For real, a friend of mine (17) works at a McDonald\\'s and his manager does cocaine at work regularly, as well as encouraging my friend to do so too. I don\\'t think it\\'s what you meant by being encouraged in some working environments but it still highlights how it\\'s a massive unchecked issue\\n\\nEdit: put \"used to do\" when in fact he still does it'\n",
            " 'DUI and murder have no upside.'\n",
            " 'Burning a dozen hives has zero impact on the human race or our ecosystem as a whole. The concern should be for the beekeeper who has thousands of dollars and many hours of labor lost. There is also an emotional element to being a victim of a property crime, but the only victim is the beekeeper. Honeybees are great, but anyone can mail order them along with hive supplies and do some beekeeping. The honeybee industry is doing just fine. Arson and felony charges are pretty serious consequences. We are going to be just fine.'\n",
            " \"I am so sorry to hear that, friend. Please don't hesitate to reach out to talk to someone. I can only imagine how you're feeling\"\n",
            " \"it's an american tradition to ruthlessly insult other states. i even insult my own state all the time.\"\n",
            " 'Good point. We should just get rid of metal detectors everywhere. They’re useless.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERTを使ってトークン化するので、BertTokenizerをロードする\n",
        "\n",
        "※最初にtransformersをインポートしていないとエラーが起こるので、必ずtransformersをインポートしてから行う\n",
        "\n",
        "トークン化に使う事前訓練モデルの選択もここで行う(bert-base-uncasedのこと)\n",
        "\n",
        "事前訓練モデルは他にも種類があるので、必要に応じて適切なものを選択する"
      ],
      "metadata": {
        "id": "yo9AhnTXOeTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GGzex042agA",
        "outputId": "457198a4-66b3-4a9b-ad60-3516eef908fb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERT tokenizerの中身を確認する"
      ],
      "metadata": {
        "id": "kKCq2JkwPExK"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVWEoGPfoPpF",
        "outputId": "3cfdc2ba-e6fb-4ee8-9381-8104956a8cc1"
      },
      "source": [
        "tokenizer"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PreTrainedTokenizer(name_or_path='bert-base-uncased', vocab_size=30522, model_max_len=512, is_fast=False, padding_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "トークン化された内容の一例を出力する\n",
        "\n",
        "まず元の文章、2番目にはトークン化のために区切られrた文章、3番目には学習と検証のためにIDが割り振られたものが出力される。"
      ],
      "metadata": {
        "id": "ljgjD1bSPIkJ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfKYmw-zoUK6",
        "outputId": "fa200d5d-c183-4f75-cd20-5c08f1ae62b2"
      },
      "source": [
        "#元の文章\n",
        "print(' Original: ', bodys[1])\n",
        "#トークン化された文章\n",
        "print('Tokenized: ', tokenizer.tokenize(bodys[1]))\n",
        "#BERTが理解できるIDが割り振られた文章\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(bodys[1])))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Original:  People do suck.  You need structured, consistent rules... ie laws.   They need to be fair, and equally applied.\n",
            "\n",
            "Groups of people don't do that... they get pitchforks and torches.\n",
            "\n",
            "&amp;#x200B;\n",
            "\n",
            "I am amazed this is an unpopular stance.\n",
            "Tokenized:  ['people', 'do', 'suck', '.', 'you', 'need', 'structured', ',', 'consistent', 'rules', '.', '.', '.', 'ie', 'laws', '.', 'they', 'need', 'to', 'be', 'fair', ',', 'and', 'equally', 'applied', '.', 'groups', 'of', 'people', 'don', \"'\", 't', 'do', 'that', '.', '.', '.', 'they', 'get', 'pitchfork', '##s', 'and', 'torches', '.', '&', 'amp', ';', '#', 'x', '##200', '##b', ';', 'i', 'am', 'amazed', 'this', 'is', 'an', 'unpopular', 'stance', '.']\n",
            "Token IDs:  [2111, 2079, 11891, 1012, 2017, 2342, 14336, 1010, 8335, 3513, 1012, 1012, 1012, 29464, 4277, 1012, 2027, 2342, 2000, 2022, 4189, 1010, 1998, 8053, 4162, 1012, 2967, 1997, 2111, 2123, 1005, 1056, 2079, 2008, 1012, 1012, 1012, 2027, 2131, 22355, 2015, 1998, 24711, 1012, 1004, 23713, 1025, 1001, 1060, 28332, 2497, 1025, 1045, 2572, 15261, 2023, 2003, 2019, 19657, 11032, 1012]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "前のコードでは一つしかトークン化を行わなかったので、ここでは分類に使う全ての文章をトークン化する\n",
        "\n",
        "スペシャルトークン[SEP]と[MASK]はここで挿入を行う"
      ],
      "metadata": {
        "id": "kA8ZRK4kPn2y"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUsAcl1EHw3F",
        "outputId": "f1802d07-b456-4e8d-b32e-bf220dffcedb"
      },
      "source": [
        "input_ids = []\n",
        "\n",
        "#bodysに格納されている全ての文章に対して行う\n",
        "for sent in bodys:\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        str(sent),                     \n",
        "                        add_special_tokens = True, \n",
        "                   )\n",
        "\n",
        "    input_ids.append(encoded_sent)\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "MAX_LEN = 64\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "attention_masks = []\n",
        "\n",
        "\n",
        "for sent in input_ids:\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    attention_masks.append(att_mask)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (765 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ここで学習用データと検証用データに分ける作業を行う\n",
        "\n",
        "train_test_splitを行うことで学習用データと検証用データに分割することができる\n",
        "\n",
        "test_sizeの値を調整すればどのくらいの割合で学習用データと検証用データを分けるかを変えられる"
      ],
      "metadata": {
        "id": "pd5HZJtxXOhf"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38A6GW3kv5cf"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_inputs, validation_inputs, train_subreddits, validation_subreddits = train_test_split(input_ids, subreddits, \n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, subreddits,\n",
        "                                             random_state=2018, test_size=0.1)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "分けた学習用データと検証用データをそれぞれのデータローダに格納する\n",
        "\n",
        "学習と検証はBERT modelを動かす時に全く別の段階で行うので、事前に分けておく必要がある"
      ],
      "metadata": {
        "id": "-yC9yb2gXTY7"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLdBvHg8wJQn"
      },
      "source": [
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_subreddits = torch.tensor(train_subreddits)\n",
        "validation_subreddits = torch.tensor(validation_subreddits)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "バッチサイズの定義を行い、その上で学習用、検証用それぞれのデータローダに格納を行う\n",
        "\n",
        "今回は推奨されている値で行なった"
      ],
      "metadata": {
        "id": "7R6-iV3YdmfY"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIQ1JyFr80-Y"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "batch_size =32\n",
        "\n",
        "#学習用データをBERT modelが読み込めるデータローダーに格納する\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_subreddits)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "#評価用データをBERT modelが読み込めるデータローダーに格納する\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_subreddits)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "モデルの構築の前に学習用、検証用のデータが必要数格納されているかを確認する"
      ],
      "metadata": {
        "id": "-tyxG-ulSkkp"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGPGeiJUVujP",
        "outputId": "19f86e55-1142-4c57-96e4-e9dc1f7a4cf4"
      },
      "source": [
        "print(\"length of train data:\",len(train_data))\n",
        "print(\"length of validation data:\",len(validation_data))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of train data: 9000\n",
            "length of validation data: 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.BERT modelの構築"
      ],
      "metadata": {
        "id": "0D0L1SGOX7Vo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "入力に使うデータが出揃ってから、BERT modelの構築を行う。\n",
        "\n",
        "モデルは必要に応じて適したものを選択する。\n",
        "\n",
        "pretrained modelはトークン化の前に定義したものと同じものを使う。\n",
        "\n",
        "num_labels は今回は2値分類なので2と示す。\n",
        "\n",
        "分類数に応じてnum_labelsの値を変える。"
      ],
      "metadata": {
        "id": "o7hSEeORXaNo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XqEpQy7Gxb78"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GVNU1HErqst",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fc0c4f2-102e-4e48-b684-ec05b9ca55ed"
      },
      "source": [
        "#BERT modelを定義する\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", \n",
        "    num_labels = 2, \n",
        "    output_attentions = False, \n",
        "    output_hidden_states = False, )\n",
        "#pytorchにこのモデルをGPU上で動かすために以下のコードで指示を出す\n",
        "model.cuda()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "（推奨事項）\n",
        "学習と検証を行う前に一旦各変数の内容の確認を行う"
      ],
      "metadata": {
        "id": "YElRfc-STAKK"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGbGAoaKsF3l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "221d21da-59ba-49a1-c42e-f02249a2808e"
      },
      "source": [
        "whos"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variable                        Type                             Data/Info\n",
            "--------------------------------------------------------------------------\n",
            "AdamW                           type                             <class 'transformers.optimization.AdamW'>\n",
            "BertConfig                      type                             <class 'transformers.mode<...>uration_bert.BertConfig'>\n",
            "BertForSequenceClassification   type                             <class 'transformers.mode<...>rSequenceClassification'>\n",
            "BertTokenizer                   type                             <class 'transformers.mode<...>tion_bert.BertTokenizer'>\n",
            "DataLoader                      type                             <class 'torch.utils.data.dataloader.DataLoader'>\n",
            "MAX_LEN                         int                              64\n",
            "RandomSampler                   type                             <class 'torch.utils.data.sampler.RandomSampler'>\n",
            "SequentialSampler               type                             <class 'torch.utils.data.<...>mpler.SequentialSampler'>\n",
            "TensorDataset                   type                             <class 'torch.utils.data.dataset.TensorDataset'>\n",
            "att_mask                        list                             n=64\n",
            "attention_masks                 list                             n=10000\n",
            "batch_size                      int                              32\n",
            "bodys                           ndarray                          10000: 10000 elems, type `object`, 80000 bytes\n",
            "count_df                        DataFrame                                      subreddit  <...>         worldnews  25000\n",
            "device                          device                           cuda\n",
            "df                              DataFrame                                subreddit        <...>n[10000 rows x 2 columns]\n",
            "df_0                            DataFrame                                subreddit        <...>n[25000 rows x 2 columns]\n",
            "df_1                            DataFrame                                subreddit        <...>n[25000 rows x 2 columns]\n",
            "discard_0                       DataFrame                                subreddit        <...>n[20000 rows x 2 columns]\n",
            "discard_1                       DataFrame                                subreddit        <...>n[20000 rows x 2 columns]\n",
            "encoded_sent                    list                             n=49\n",
            "input_ids                       ndarray                          10000x64: 640000 elems, type `int64`, 5120000 bytes (4.8828125 Mb)\n",
            "list                            list                             n=2\n",
            "model                           BertForSequenceClassification    BertForSequenceClassifica<...>features=2, bias=True)\\n)\n",
            "pad_sequences                   function                         <function pad_sequences at 0x7f59782c5440>\n",
            "pd                              module                           <module 'pandas' from '/u<...>ages/pandas/__init__.py'>\n",
            "sent                            ndarray                          64: 64 elems, type `int64`, 512 bytes\n",
            "split_dataset_0                 DataFrame                                subreddit        <...>\\n[5000 rows x 2 columns]\n",
            "split_dataset_1                 DataFrame                                subreddit        <...>\\n[5000 rows x 2 columns]\n",
            "subreddits                      ndarray                          10000: 10000 elems, type `int64`, 80000 bytes\n",
            "tf                              module                           <module 'tensorflow' from<...>/tensorflow/__init__.py'>\n",
            "tokenizer                       BertTokenizer                    PreTrainedTokenizer(name_<...> 'mask_token': '[MASK]'})\n",
            "torch                           module                           <module 'torch' from '/us<...>kages/torch/__init__.py'>\n",
            "train_data                      TensorDataset                    <torch.utils.data.dataset<...>object at 0x7f585f53b310>\n",
            "train_dataloader                DataLoader                       <torch.utils.data.dataloa<...>object at 0x7f585f53b650>\n",
            "train_inputs                    Tensor                           tensor([[  101,  1004, 14<...>.,     0,     0,     0]])\n",
            "train_masks                     Tensor                           tensor([[1, 1, 1,  ..., 0<...>1, 1, 1,  ..., 0, 0, 0]])\n",
            "train_sampler                   RandomSampler                    <torch.utils.data.sampler<...>object at 0x7f585f53b710>\n",
            "train_subreddits                Tensor                           tensor([1, 0, 0,  ..., 0, 0, 1])\n",
            "train_test_split                function                         <function train_test_split at 0x7f5857a89dd0>\n",
            "validation_data                 TensorDataset                    <torch.utils.data.dataset<...>object at 0x7f58551fb350>\n",
            "validation_dataloader           DataLoader                       <torch.utils.data.dataloa<...>object at 0x7f58551fba90>\n",
            "validation_inputs               Tensor                           tensor([[ 101, 3342, 2043<...> ...,    0,    0,    0]])\n",
            "validation_masks                Tensor                           tensor([[1, 1, 1,  ..., 0<...>1, 1, 1,  ..., 0, 0, 0]])\n",
            "validation_sampler              SequentialSampler                <torch.utils.data.sampler<...>object at 0x7f58551fb950>\n",
            "validation_subreddits           Tensor                           tensor([1, 0, 0, 0, 1, 1,<...> 1, 1, 1, 1, 1, 1, 1, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "（推奨事項）もし学習と検証の段階でcuda errorが起こった場合、その原因がおそらくlistと考えられる\n",
        "\n",
        "以降ではlistの中身を使うことがないので削除して問題ない"
      ],
      "metadata": {
        "id": "ds-YJcCSTKve"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5vnKQq1sHuc"
      },
      "source": [
        "del list"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERTモデルの中身及びパラメータを確認する時には以下のセルを実行する"
      ],
      "metadata": {
        "id": "jw3ss3B-QOSt"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXobR03zsHyh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5772fbfe-5672-4e51-a5be-724f0e2990f1"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "optimizerの値を決定する(今回はHugging Faceが推奨する値で行なったが、変更も可能)"
      ],
      "metadata": {
        "id": "hnDPEBZXQU3h"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQmmZgnesJb0"
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "エポック数を決める(今回はHugging Faceが推奨する値で行なったが、変更も可能)"
      ],
      "metadata": {
        "id": "RDdt6sCMQZrh"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJLAsdgZsL_Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7aa4772-2f1d-4600-ce16-19ca70e450ff"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n",
        "scheduler"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.optim.lr_scheduler.LambdaLR at 0x7f585d041e50>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "正解率の計算式を定義する(今回はHugging Faceが推奨する式で行なったが、場合に応じては変更も可能)\n"
      ],
      "metadata": {
        "id": "oAtYrNAjQbE8"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMgLdT0LsO8t"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "（推奨事項）学習と検証にかかった時間を知るために、時間の計算の値を返すように設定する"
      ],
      "metadata": {
        "id": "vGhs-cXrQfY-"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FJbbti9sSNW"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    #フォーマットは hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.学習と検証を行う\n"
      ],
      "metadata": {
        "id": "8qSUEuC4Qsp6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "#(推奨事項)損失関数を格納するためのリストを作る\n",
        "loss_values = []\n",
        "\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "  \n",
        "    #=======================#\n",
        "\n",
        "                #学習\n",
        "\n",
        "    #=======================#\n",
        " \n",
        "\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    #(推奨事項)学習時間の計測を行う\n",
        "    t0 = time.time()\n",
        "    total_loss = 0\n",
        "\n",
        "    #学習のためのモデルを動かす\n",
        "    model.train()\n",
        "\n",
        "    #(推奨事項)学習の進捗状況を出力する\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        if step % 100 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "\n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "\n",
        "        loss = outputs[0]\n",
        "        total_loss += loss.item()\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    #(推奨事項)損失関数の計算を行う\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    #(推奨事項)各epochで得られた損失関数をlistに格納する\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.4f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "\n",
        "    #=======================#\n",
        "\n",
        "                #検証\n",
        "                \n",
        "    #=======================#\n",
        "    \n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    #(推奨事項)検証にかかった時間を計算する\n",
        "    #学習にかかった時間が入っているので一度リセットする\n",
        "    t0 = time.time()\n",
        "\n",
        "    #検証のためのモデルを動かす\n",
        "    model.eval()\n",
        "\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "\n",
        "    for batch in validation_dataloader:\n",
        "         batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        with torch.no_grad():        \n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        logits = outputs[0]\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        #正解率の計算を行う\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    #検証結果の出力を行う\n",
        "    print(\"  Accuracy: {0:.4f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2YU-N8mAFZY",
        "outputId": "a2a4ec25-fb38-4a18-b0ec-8ecbdf8b5545"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch   100  of    282.    Elapsed: 0:00:21.\n",
            "  Batch   200  of    282.    Elapsed: 0:00:41.\n",
            "\n",
            "  Average training loss: 0.1752\n",
            "  Training epcoh took: 0:00:58\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.7480\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch   100  of    282.    Elapsed: 0:00:21.\n",
            "  Batch   200  of    282.    Elapsed: 0:00:41.\n",
            "\n",
            "  Average training loss: 0.1528\n",
            "  Training epcoh took: 0:00:58\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.7480\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch   100  of    282.    Elapsed: 0:00:21.\n",
            "  Batch   200  of    282.    Elapsed: 0:00:41.\n",
            "\n",
            "  Average training loss: 0.1539\n",
            "  Training epcoh took: 0:00:58\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.7480\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch   100  of    282.    Elapsed: 0:00:21.\n",
            "  Batch   200  of    282.    Elapsed: 0:00:41.\n",
            "\n",
            "  Average training loss: 0.1828\n",
            "  Training epcoh took: 0:00:58\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.7480\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "（推奨事項）損失関数を求める"
      ],
      "metadata": {
        "id": "-coS3-huTsR7"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDepN0AbHIef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acd00518-f870-4e8c-b075-950bc121499b"
      },
      "source": [
        "loss_values"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.17518191870486904,\n",
              " 0.15275603333316373,\n",
              " 0.1538533369171704,\n",
              " 0.1827706863958362]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "（推奨事項）損失関数によるグラフの作成"
      ],
      "metadata": {
        "id": "b8xoHSxrTvA0"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1alxJ4duxCA0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "bbd024e6-e7d8-4cf7-c634-9e7cc3c62682"
      },
      "source": [
        "import plotly.express as px\n",
        "\n",
        "f = pd.DataFrame(loss_values)\n",
        "f.columns=['Loss']\n",
        "fig = px.line(f, x=f.index, y=f.Loss)\n",
        "fig.update_layout(title='Training loss of the Model',\n",
        "                   xaxis_title='Epoch',\n",
        "                   yaxis_title='Loss')\n",
        "fig.show()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"25c5fd9f-9cbb-4430-8a6c-041a47c806b5\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"25c5fd9f-9cbb-4430-8a6c-041a47c806b5\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '25c5fd9f-9cbb-4430-8a6c-041a47c806b5',\n",
              "                        [{\"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"index=%{x}<br>Loss=%{y}\", \"legendgroup\": \"\", \"line\": {\"color\": \"#636efa\", \"dash\": \"solid\"}, \"mode\": \"lines\", \"name\": \"\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [0, 1, 2, 3], \"xaxis\": \"x\", \"y\": [0.17518191870486904, 0.15275603333316373, 0.1538533369171704, 0.1827706863958362], \"yaxis\": \"y\"}],\n",
              "                        {\"legend\": {\"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Training loss of the Model\"}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Epoch\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Loss\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('25c5fd9f-9cbb-4430-8a6c-041a47c806b5');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "分類器を構築し、性能評価を行う段階は以上。\n",
        "\n",
        "以降は分類器をテストする際に実行をしたプログラムである。\n",
        "\n",
        "テスト用のipynbファイルを作り直すと、学習と検証のために使った分類器の内容が消されてしまうので、テストを行うのであれば、同一のipynbファイル内で実行する必要がある。"
      ],
      "metadata": {
        "id": "VMfMBMpxTyK2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7.テスト"
      ],
      "metadata": {
        "id": "T6_wteB3YZ5I"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wELlVP2ZmbEs"
      },
      "source": [
        "テストを行う際には以下のセルを実行する\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "学習と検証用に選択したカテゴリー名と同一のものをテストでも使う必要がある。\n",
        "\n",
        "先程1カテゴリー25000から使用しなかった20000個から抽出をした。\n",
        "\n",
        "これによって学習と検証で使ったデータをテストでも重複して使うということをなくした。\n",
        "\n",
        "テストの前段階では学習と検証に用いた文章データと同様にBERTに入力できるように設定をした。\n",
        "\n",
        "テストを終えた後では、テスト結果から得られた数値を求め、可視化を行なった。"
      ],
      "metadata": {
        "id": "SXfNp3eMYcuk"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTBmN-I0dZbT",
        "outputId": "c19edf77-50dd-475a-d9dd-7ed644a555bf"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "split_dataset_test_0,discard_test_0=train_test_split(discard_0, train_size=(1000/(25000-5000))) \n",
        "print(\"使えるデータセット\")\n",
        "print(split_dataset_test_0)\n",
        "\n",
        "split_dataset_test_1 ,discard_test_1= train_test_split(discard_1, train_size=(1000/(25000-5000)))\n",
        "print(\"使えるデータセット\")\n",
        "print(split_dataset_test_1)\n",
        "\n",
        "\n",
        "list=[]\n",
        "list.append(split_dataset_test_0)\n",
        "list.append(split_dataset_test_1)\n",
        "\n",
        "df = pd.concat(list, sort=False)\n",
        "print(df)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "使えるデータセット\n",
            "        subreddit                                               body\n",
            "25422           0                 Three deaths is nothing in the US.\n",
            "298341          0  Kill unarmed civilians because your feelings a...\n",
            "765317          0             they're gonna harrass someone for this\n",
            "199995          0  You are defending a traitor. Just remember whe...\n",
            "761751          0  For $6 million you could hire someone to get p...\n",
            "...           ...                                                ...\n",
            "66494           0              He didn't write a letter to the media\n",
            "462938          0  &gt;At that time, Nance said Turner went back ...\n",
            "678950          0  well maybe they should have let out the people...\n",
            "723822          0  That's how the US is operating at this point. ...\n",
            "280655          0  It's not just \"taking off the condom\" it's whe...\n",
            "\n",
            "[1000 rows x 2 columns]\n",
            "使えるデータセット\n",
            "        subreddit                                               body\n",
            "22652           1  US  sanctions were only placed very recently o...\n",
            "675472          1  I'd love to think that this will finally put t...\n",
            "6327            1  Battle of Athens 1946, we have done it in the ...\n",
            "47250           1  I wonder if roundup weed killer know what vide...\n",
            "313048          1                              No need to \"act like\"\n",
            "...           ...                                                ...\n",
            "670921          1  The problem is that most of the bombs had alre...\n",
            "248626          1  Not at all.\\n\\nIt means: \\n&gt; compulsion by ...\n",
            "475152          1  Hi OniNisan. Your submission from nytimes.com ...\n",
            "515133          1  Well seeing as Mueller Knows what was in the r...\n",
            "636955          1      This. It's basically an umbrella corporation.\n",
            "\n",
            "[1000 rows x 2 columns]\n",
            "        subreddit                                               body\n",
            "25422           0                 Three deaths is nothing in the US.\n",
            "298341          0  Kill unarmed civilians because your feelings a...\n",
            "765317          0             they're gonna harrass someone for this\n",
            "199995          0  You are defending a traitor. Just remember whe...\n",
            "761751          0  For $6 million you could hire someone to get p...\n",
            "...           ...                                                ...\n",
            "670921          1  The problem is that most of the bombs had alre...\n",
            "248626          1  Not at all.\\n\\nIt means: \\n&gt; compulsion by ...\n",
            "475152          1  Hi OniNisan. Your submission from nytimes.com ...\n",
            "515133          1  Well seeing as Mueller Knows what was in the r...\n",
            "636955          1      This. It's basically an umbrella corporation.\n",
            "\n",
            "[2000 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7PuJIGM342n",
        "outputId": "4778a4d3-f64b-494a-ad8a-cffa7c8fa9c0"
      },
      "source": [
        "print(df.sample(10))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        subreddit                                               body\n",
            "613070          1  Honestly, even if Guiado takes over from Madur...\n",
            "746991          0  PLA foam (which is biodegradable) is a suitabl...\n",
            "644922          0  maybe that’s why they’re always so pinchy, the...\n",
            "555124          1  For the record: I never said users do not bear...\n",
            "566475          0  &gt;Also, getting fired is a bit different fro...\n",
            "363169          1  Modern formula is nearly identical to breast m...\n",
            "450066          1  Yes, I bet John Bolton and Donald \"We take the...\n",
            "8384            1  Taking the line of “it’s not ‘democratic,’ eve...\n",
            "364786          1  Having owned four different Huawei phones (inc...\n",
            "635696          0  There are laws in place against arson and dest...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfHQ3AmN342n"
      },
      "source": [
        "subreddits = df.subreddit.values\n",
        "bodys = df.body.values"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5guwNZIF342n",
        "outputId": "83abf2f4-94cc-4e31-8ea4-fd709e662169"
      },
      "source": [
        "print(bodys[1:10])"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Kill unarmed civilians because your feelings are hurt vs kill armed soldiers who are being told to do the same to you? Both are pretty natural throughout history. Honestly, modern times are better by A LOT in my opinion. The real fucked up part is the ones that die in both scenarios are, in a lot of ways, still children.'\n",
            " \"they're gonna harrass someone for this\"\n",
            " \"You are defending a traitor. Just remember when all this is over you are scum who betrayed your country in it's time of need.\"\n",
            " \"For $6 million you could hire someone to get plastic surgery to be a body double that's actually smart to actually attend the classes and take the tests.\"\n",
            " 'What about the innocent lives that the guns save though? I can link you 4-5 news articles from the last month alone where guns were used against intruders, or in one case someone pulled out a gun to prevent a little girl from being kidnapped.\\n\\nThese are all things you have to weigh before deciding to strip guns away.'\n",
            " '&gt; \"Your honor, I object! It\\'s devastating to my case!\"\\n\\nObjection! That proves I\\'m guilty!'\n",
            " \"Riley Howell is the hero's name\"\n",
            " 'No but definitely remove mega churches and tax incentives.'\n",
            " \"Looool I've had this exact argument at 4am at a party with a guy hardcore judging me for having a cup of tea with cows milk when he was coked off his nut.\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERTでの分類に向けた準備\n",
        "\n",
        "テスト用データでもBERTでの分類に適した形にデータのトークン化を行なった"
      ],
      "metadata": {
        "id": "1agWTQXoqB2Y"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFwF6uHz342n",
        "outputId": "8cb1bcb3-9e16-4df5-9d96-70023df0f8ee"
      },
      "source": [
        "input_ids = []\n",
        "\n",
        "for sent in bodys:\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        str(sent),                    \n",
        "                        add_special_tokens = True,\n",
        "                   )\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "MAX_LEN = 64\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "attention_masks = []\n",
        "\n",
        "\n",
        "for sent in input_ids:\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    attention_masks.append(att_mask)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Padding/truncating all sentences to 64 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "テスト用のデータを分類器に入力をするための準備を行う。"
      ],
      "metadata": {
        "id": "WtMO0k9OoeaL"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xkHGueVUWa-"
      },
      "source": [
        "test_inputs=input_ids\n",
        "test_subreddits=subreddits\n",
        "test_masks=attention_masks"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcBvuNdyUWa_"
      },
      "source": [
        "test_inputs = torch.tensor(test_inputs)\n",
        "\n",
        "test_subreddits = torch.tensor(test_subreddits)\n",
        "\n",
        "test_masks = torch.tensor(test_masks)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_HT2vZA9MiQ"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "batch_size = 32\n",
        "\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_subreddits)\n",
        "test_sampler = RandomSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgUaHNRt3qa6"
      },
      "source": [
        "test_data = TensorDataset(test_inputs, test_masks, test_subreddits)\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyKPEEo36tw0",
        "outputId": "745c0711-de9b-467e-def7-d53d271191fa"
      },
      "source": [
        "len(test_data)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "cudaが使えるかどうかの確認を行う"
      ],
      "metadata": {
        "id": "x4AeiAdNhYnA"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NV-eVNIql9C",
        "outputId": "84e9ee91-d775-4872-f485-35a807bf546d"
      },
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G20kBKPKqyAj",
        "outputId": "bdf6e74d-67cf-45f2-d644-84536c75165a"
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "テスト用データを使って分類を行う\n",
        "\n",
        "分類器は先程学習と検証を行なったものを呼び出して行う"
      ],
      "metadata": {
        "id": "QLzMOCZUSo81"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIh7osycmZJr",
        "outputId": "227034ac-c7aa-4708-e765-97574546deb6"
      },
      "source": [
        "#=======================#\n",
        "\n",
        "             #テスト\n",
        "                \n",
        "#=======================#\n",
        "\n",
        "#(推奨事項)テストにかかった時間を計算する\n",
        "t0 = time.time()\n",
        "\n",
        "for batch in validation_dataloader:\n",
        "\n",
        "    b_input_ids =test_inputs\n",
        "    b_input_mask = test_masks\n",
        "    b_labels = test_subreddits\n",
        "    b_input_ids = b_input_ids.to(device)\n",
        "    b_input_mask = b_input_mask.to(device)\n",
        "    b_labels = b_labels.to(device)\n",
        "    \n",
        "    with torch.no_grad():   \n",
        "        # 学習済みモデルによる予測結果をpredsで取得する     \n",
        "      preds = model(b_input_ids, \n",
        "                     token_type_ids=None, \n",
        "                     attention_mask=b_input_mask)\n",
        "\n",
        "print(\"time took : {:}\".format(format_time(time.time() - t0)))"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time took : 0:01:47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*テスト結果の確認*"
      ],
      "metadata": {
        "id": "I4Cpand7NFtY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "テスト用データによる分類結果をlogits_dfに入れる\n",
        "\n",
        "予測ラベルと正解ラベルのデータも同様にpred_dfとlabel_dfに入れる\n",
        "\n",
        "３つのデータをaccuracy_dfに入れることでテスト結果の一部を見れるようにする\n",
        "\n",
        "今回テストに用いた2000個の文章データ1つ1つが、テストをした結果どこのカテゴリー名であると割り振られ、実際にはどこのカテゴリー名であったかをaccuracy_dfを得ることによって確認ができる"
      ],
      "metadata": {
        "id": "Vp-xlFibSxx0"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "wLTnxlUmsPbl",
        "outputId": "94fcf3e5-d4bc-4ef0-c806-4f61d8eeafbc"
      },
      "source": [
        "# 比較しやすい様にpd.dataframeへ整形\n",
        "import pandas as pd\n",
        "\n",
        "# pd.dataframeへ変換（GPUに乗っているTensorはgpu->cpu->numpy->dataframeと変換）\n",
        "logits_df = pd.DataFrame(preds[0].cpu().numpy() )\n",
        "## np.argmaxで大き方の値を取得\n",
        "pred_df = pd.DataFrame(np.argmax(preds[0].cpu().numpy(), axis=1), columns=['pred_label'])\n",
        "label_df = pd.DataFrame(b_labels.cpu().numpy(), columns=['true_label'])\n",
        "\n",
        "accuracy_df = pd.concat([logits_df, pred_df, label_df], axis=1)\n",
        "\n",
        "accuracy_df.head(10)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4ce84454-c210-4500-af5c-e92617f9d83b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>pred_label</th>\n",
              "      <th>true_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.291042</td>\n",
              "      <td>-1.338447</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.962890</td>\n",
              "      <td>1.713593</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.480808</td>\n",
              "      <td>-0.366686</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.373219</td>\n",
              "      <td>1.187297</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.927945</td>\n",
              "      <td>-1.557997</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.965668</td>\n",
              "      <td>-2.253903</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1.722731</td>\n",
              "      <td>-1.365973</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.574921</td>\n",
              "      <td>-1.707006</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.955299</td>\n",
              "      <td>-0.701091</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1.442177</td>\n",
              "      <td>-1.242801</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4ce84454-c210-4500-af5c-e92617f9d83b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4ce84454-c210-4500-af5c-e92617f9d83b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4ce84454-c210-4500-af5c-e92617f9d83b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "          0         1  pred_label  true_label\n",
              "0  1.291042 -1.338447           0           0\n",
              "1 -0.962890  1.713593           1           0\n",
              "2  0.480808 -0.366686           0           0\n",
              "3 -0.373219  1.187297           1           0\n",
              "4  1.927945 -1.557997           0           0\n",
              "5  1.965668 -2.253903           0           0\n",
              "6  1.722731 -1.365973           0           0\n",
              "7  1.574921 -1.707006           0           0\n",
              "8  0.955299 -0.701091           0           0\n",
              "9  1.442177 -1.242801           0           0"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "テスト結果を元に混合行列を作る\n",
        "\n",
        "ここでは混合行列を数値データで出力する"
      ],
      "metadata": {
        "id": "HMNj5tVURW17"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67oSJwJzPJZo",
        "outputId": "bafa04f3-f846-44cd-e82a-aa950a7c0de5"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cmatrix = confusion_matrix(label_df,pred_df)\n",
        "print(cmatrix)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[727 273]\n",
            " [275 725]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "必要に応じて混合行列を図として出力する"
      ],
      "metadata": {
        "id": "_C6svBwbRDSw"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "id": "kU4_9ymEwccX",
        "outputId": "73fd1ab0-9eaf-4d13-cb8a-a695d03d81d4"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.title(\"low cos similality 2 classes\")\n",
        "plt.rcParams[\"font.size\"] = 16\n",
        "sns.heatmap(cmatrix, cmap= sns.color_palette('rainbow', 50), annot=True,fmt='.0f',vmin=0,vmax=1000)\n"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f585f15f690>"
            ]
          },
          "metadata": {},
          "execution_count": 94
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmUjbDLdApmn"
      },
      "source": [
        "from sklearn import metrics"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "テスト結果を数値で出力する"
      ],
      "metadata": {
        "id": "Ka8LXEHVRiiP"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3JdR0Mw_EvD",
        "outputId": "8ff7dfa3-810e-481b-a5c8-6efd2b3e4cd6"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(\"Classification report\")\n",
        "print(classification_report(label_df,pred_df))"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.73      0.73      1000\n",
            "           1       0.73      0.72      0.73      1000\n",
            "\n",
            "    accuracy                           0.73      2000\n",
            "   macro avg       0.73      0.73      0.73      2000\n",
            "weighted avg       0.73      0.73      0.73      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0z8e7qeW9jYP",
        "outputId": "5b775d9d-dc3a-4528-9db3-a51518c339d6"
      },
      "source": [
        "import pprint\n",
        "d = metrics.classification_report(label_df,pred_df, output_dict=True)\n",
        "pprint.pprint(d)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'0': {'f1-score': 0.7262737262737263,\n",
            "       'precision': 0.7255489021956087,\n",
            "       'recall': 0.727,\n",
            "       'support': 1000},\n",
            " '1': {'f1-score': 0.7257257257257258,\n",
            "       'precision': 0.7264529058116233,\n",
            "       'recall': 0.725,\n",
            "       'support': 1000},\n",
            " 'accuracy': 0.726,\n",
            " 'macro avg': {'f1-score': 0.7259997259997261,\n",
            "               'precision': 0.7260009040036159,\n",
            "               'recall': 0.726,\n",
            "               'support': 2000},\n",
            " 'weighted avg': {'f1-score': 0.7259997259997261,\n",
            "                  'precision': 0.726000904003616,\n",
            "                  'recall': 0.726,\n",
            "                  'support': 2000}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "テスト結果を表で出力する"
      ],
      "metadata": {
        "id": "u0n0DwIXSftu"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "VuCTI965HfkZ",
        "outputId": "bf918638-09bd-4541-8f0f-6faf90cabebf"
      },
      "source": [
        "df = pd.DataFrame(d)\n",
        "df"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8c6dda2d-5466-4200-92ed-7be5827815b8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro avg</th>\n",
              "      <th>weighted avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.725549</td>\n",
              "      <td>0.726453</td>\n",
              "      <td>0.726</td>\n",
              "      <td>0.726001</td>\n",
              "      <td>0.726001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.727000</td>\n",
              "      <td>0.725000</td>\n",
              "      <td>0.726</td>\n",
              "      <td>0.726000</td>\n",
              "      <td>0.726000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.726274</td>\n",
              "      <td>0.725726</td>\n",
              "      <td>0.726</td>\n",
              "      <td>0.726000</td>\n",
              "      <td>0.726000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>0.726</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8c6dda2d-5466-4200-92ed-7be5827815b8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8c6dda2d-5466-4200-92ed-7be5827815b8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8c6dda2d-5466-4200-92ed-7be5827815b8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                     0            1  accuracy    macro avg  weighted avg\n",
              "precision     0.725549     0.726453     0.726     0.726001      0.726001\n",
              "recall        0.727000     0.725000     0.726     0.726000      0.726000\n",
              "f1-score      0.726274     0.725726     0.726     0.726000      0.726000\n",
              "support    1000.000000  1000.000000     0.726  2000.000000   2000.000000"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "必要に応じてテスト結果を図で出力する"
      ],
      "metadata": {
        "id": "6qYpyTnqSiiO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.rcParams[\"font.size\"] = 12\n",
        "plt.title(\"low cos similality 2 classes\")\n",
        "sns.heatmap(df, cmap= sns.color_palette('rainbow', 40), annot=True,fmt='.4f',vmin=0,vmax=1,linewidths=1,linecolor='white')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "Z0wKPhhxSas2",
        "outputId": "0f606c1c-d9ad-4756-d778-2972856be0a0"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f585c716750>"
            ]
          },
          "metadata": {},
          "execution_count": 101
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}